{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc6ab93-eb19-466d-acf1-f7a1858bd92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a83f43b-3d87-48e2-86fa-b98c4f26e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cdsapi\n",
      "  Downloading cdsapi-0.7.6-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting ecmwf-datastores-client (from cdsapi)\n",
      "  Downloading ecmwf_datastores_client-0.1.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests>=2.5.0 in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from cdsapi) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from cdsapi) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from requests>=2.5.0->cdsapi) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from requests>=2.5.0->cdsapi) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from requests>=2.5.0->cdsapi) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from requests>=2.5.0->cdsapi) (2025.4.26)\n",
      "Requirement already satisfied: attrs in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from ecmwf-datastores-client->cdsapi) (25.3.0)\n",
      "Collecting multiurl>=0.3.2 (from ecmwf-datastores-client->cdsapi)\n",
      "  Downloading multiurl-0.3.5-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from ecmwf-datastores-client->cdsapi) (4.13.2)\n",
      "Requirement already satisfied: pytz in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from multiurl>=0.3.2->ecmwf-datastores-client->cdsapi) (2025.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from multiurl>=0.3.2->ecmwf-datastores-client->cdsapi) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jacaraba/.local/share/mamba/envs/triton-infer-env3/lib/python3.10/site-packages (from python-dateutil->multiurl>=0.3.2->ecmwf-datastores-client->cdsapi) (1.17.0)\n",
      "Downloading cdsapi-0.7.6-py2.py3-none-any.whl (12 kB)\n",
      "Downloading ecmwf_datastores_client-0.1.0-py3-none-any.whl (29 kB)\n",
      "Downloading multiurl-0.3.5-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: multiurl, ecmwf-datastores-client, cdsapi\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [cdsapi]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cdsapi-0.7.6 ecmwf-datastores-client-0.1.0 multiurl-0.3.5\n"
     ]
    }
   ],
   "source": [
    "!pip install cdsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba739f4-4851-4b6b-8efc-f643a913e5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 11:26:48,126 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2025-05-28 11:26:49,069 INFO Request ID is 791ee24e-5ab4-4694-960d-36f5c9756834\n",
      "2025-05-28 11:26:49,216 INFO status has been updated to accepted\n",
      "2025-05-28 11:27:10,951 INFO status has been updated to running\n",
      "2025-05-28 11:27:22,507 INFO status has been updated to successful\n",
      "                                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static variables downloaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 11:27:28,156 INFO Request ID is d6917a47-d564-4a48-88af-e0e2ef0e56b8\n",
      "2025-05-28 11:27:28,288 INFO status has been updated to accepted\n",
      "2025-05-28 11:28:01,853 INFO status has been updated to running\n",
      "2025-05-28 11:28:19,099 INFO status has been updated to successful\n",
      "                                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surface-level variables downloaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 11:28:26,699 INFO Request ID is 8488a289-879e-4a59-a7f9-eab2186135f8\n",
      "2025-05-28 11:28:26,828 INFO status has been updated to accepted\n",
      "2025-05-28 11:28:40,859 INFO status has been updated to running\n",
      "2025-05-28 11:29:00,148 INFO status has been updated to successful\n",
      "                                                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atmospheric variables downloaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cdsapi\n",
    "\n",
    "# Data will be downloaded here.\n",
    "download_path = Path(\"~/downloads\")\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "download_path = download_path.expanduser()\n",
    "download_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download the static variables.\n",
    "if not (download_path / \"static.nc\").exists():\n",
    "    c.retrieve(\n",
    "        \"reanalysis-era5-single-levels\",\n",
    "        {\n",
    "            \"product_type\": \"reanalysis\",\n",
    "            \"variable\": [\n",
    "                \"geopotential\",\n",
    "                \"land_sea_mask\",\n",
    "                \"soil_type\",\n",
    "            ],\n",
    "            \"year\": \"2023\",\n",
    "            \"month\": \"01\",\n",
    "            \"day\": \"01\",\n",
    "            \"time\": \"00:00\",\n",
    "            \"format\": \"netcdf\",\n",
    "        },\n",
    "        str(download_path / \"static.nc\"),\n",
    "    )\n",
    "print(\"Static variables downloaded!\")\n",
    "\n",
    "# Download the surface-level variables.\n",
    "if not (download_path / \"2023-01-01-surface-level.nc\").exists():\n",
    "    c.retrieve(\n",
    "        \"reanalysis-era5-single-levels\",\n",
    "        {\n",
    "            \"product_type\": \"reanalysis\",\n",
    "            \"variable\": [\n",
    "                \"2m_temperature\",\n",
    "                \"10m_u_component_of_wind\",\n",
    "                \"10m_v_component_of_wind\",\n",
    "                \"mean_sea_level_pressure\",\n",
    "            ],\n",
    "            \"year\": \"2023\",\n",
    "            \"month\": \"01\",\n",
    "            \"day\": \"01\",\n",
    "            \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
    "            \"format\": \"netcdf\",\n",
    "        },\n",
    "        str(download_path / \"2023-01-01-surface-level.nc\"),\n",
    "    )\n",
    "print(\"Surface-level variables downloaded!\")\n",
    "\n",
    "# Download the atmospheric variables.\n",
    "if not (download_path / \"2023-01-01-atmospheric.nc\").exists():\n",
    "    c.retrieve(\n",
    "        \"reanalysis-era5-pressure-levels\",\n",
    "        {\n",
    "            \"product_type\": \"reanalysis\",\n",
    "            \"variable\": [\n",
    "                \"temperature\",\n",
    "                \"u_component_of_wind\",\n",
    "                \"v_component_of_wind\",\n",
    "                \"specific_humidity\",\n",
    "                \"geopotential\",\n",
    "            ],\n",
    "            \"pressure_level\": [\n",
    "                \"50\",\n",
    "                \"100\",\n",
    "                \"150\",\n",
    "                \"200\",\n",
    "                \"250\",\n",
    "                \"300\",\n",
    "                \"400\",\n",
    "                \"500\",\n",
    "                \"600\",\n",
    "                \"700\",\n",
    "                \"850\",\n",
    "                \"925\",\n",
    "                \"1000\",\n",
    "            ],\n",
    "            \"year\": \"2023\",\n",
    "            \"month\": \"01\",\n",
    "            \"day\": \"01\",\n",
    "            \"time\": [\"00:00\", \"06:00\", \"12:00\", \"18:00\"],\n",
    "            \"format\": \"netcdf\",\n",
    "        },\n",
    "        str(download_path / \"2023-01-01-atmospheric.nc\"),\n",
    "    )\n",
    "print(\"Atmospheric variables downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d100ee0-67c2-4533-817c-8a049fd54996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xr\n",
    "\n",
    "from aurora import Batch, Metadata\n",
    "\n",
    "static_vars_ds = xr.open_dataset(download_path / \"static.nc\", engine=\"netcdf4\")\n",
    "surf_vars_ds = xr.open_dataset(download_path / \"2023-01-01-surface-level.nc\", engine=\"netcdf4\")\n",
    "atmos_vars_ds = xr.open_dataset(download_path / \"2023-01-01-atmospheric.nc\", engine=\"netcdf4\")\n",
    "\n",
    "batch = Batch(\n",
    "    surf_vars={\n",
    "        # First select the first two time points: 00:00 and 06:00. Afterwards, `[None]`\n",
    "        # inserts a batch dimension of size one.\n",
    "        \"2t\": torch.from_numpy(surf_vars_ds[\"t2m\"].values[:2][None]),\n",
    "        \"10u\": torch.from_numpy(surf_vars_ds[\"u10\"].values[:2][None]),\n",
    "        \"10v\": torch.from_numpy(surf_vars_ds[\"v10\"].values[:2][None]),\n",
    "        \"msl\": torch.from_numpy(surf_vars_ds[\"msl\"].values[:2][None]),\n",
    "    },\n",
    "    static_vars={\n",
    "        # The static variables are constant, so we just get them for the first time.\n",
    "        \"z\": torch.from_numpy(static_vars_ds[\"z\"].values[0]),\n",
    "        \"slt\": torch.from_numpy(static_vars_ds[\"slt\"].values[0]),\n",
    "        \"lsm\": torch.from_numpy(static_vars_ds[\"lsm\"].values[0]),\n",
    "    },\n",
    "    atmos_vars={\n",
    "        \"t\": torch.from_numpy(atmos_vars_ds[\"t\"].values[:2][None]),\n",
    "        \"u\": torch.from_numpy(atmos_vars_ds[\"u\"].values[:2][None]),\n",
    "        \"v\": torch.from_numpy(atmos_vars_ds[\"v\"].values[:2][None]),\n",
    "        \"q\": torch.from_numpy(atmos_vars_ds[\"q\"].values[:2][None]),\n",
    "        \"z\": torch.from_numpy(atmos_vars_ds[\"z\"].values[:2][None]),\n",
    "    },\n",
    "    metadata=Metadata(\n",
    "        lat=torch.from_numpy(surf_vars_ds.latitude.values),\n",
    "        lon=torch.from_numpy(surf_vars_ds.longitude.values),\n",
    "        # Converting to `datetime64[s]` ensures that the output of `tolist()` gives\n",
    "        # `datetime.datetime`s. Note that this needs to be a tuple of length one:\n",
    "        # one value for every batch element. Select element 1, corresponding to time\n",
    "        # 06:00.\n",
    "        time=(surf_vars_ds.valid_time.values.astype(\"datetime64[s]\").tolist()[1],),\n",
    "        atmos_levels=tuple(int(level) for level in atmos_vars_ds.pressure_level.values),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347315b0-dcf5-4ad3-934a-9cf786b2da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurora import Aurora, rollout\n",
    "\n",
    "model = Aurora(use_lora=False)  # The pretrained version does not use LoRA.\n",
    "model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\")\n",
    "\n",
    "model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = [pred.to(\"cpu\") for pred in rollout(model, batch, steps=2)]\n",
    "\n",
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7652b6-3ad0-4b5b-b02c-c2eb72bf8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6.5))\n",
    "\n",
    "for i in range(ax.shape[0]):\n",
    "    pred = preds[i]\n",
    "\n",
    "    ax[i, 0].imshow(pred.surf_vars[\"2t\"][0, 0].numpy() - 273.15, vmin=-50, vmax=50)\n",
    "    ax[i, 0].set_ylabel(str(pred.metadata.time[0]))\n",
    "    if i == 0:\n",
    "        ax[i, 0].set_title(\"Aurora Prediction\")\n",
    "    ax[i, 0].set_xticks([])\n",
    "    ax[i, 0].set_yticks([])\n",
    "\n",
    "    ax[i, 1].imshow(surf_vars_ds[\"t2m\"][2 + i].values - 273.15, vmin=-50, vmax=50)\n",
    "    if i == 0:\n",
    "        ax[i, 1].set_title(\"ERA5\")\n",
    "    ax[i, 1].set_xticks([])\n",
    "    ax[i, 1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
